{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":191501,"sourceType":"datasetVersion","datasetId":82373},{"sourceId":11574562,"sourceType":"datasetVersion","datasetId":7256858},{"sourceId":11597836,"sourceType":"datasetVersion","datasetId":7273256},{"sourceId":11601577,"sourceType":"datasetVersion","datasetId":7276151}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ItalianSignNet study","metadata":{}},{"cell_type":"markdown","source":"### Importing Required Libraries","metadata":{"_kg_hide-output":true}},{"cell_type":"code","source":"!pip cache purge\n!pip install -q tensorflow-model-optimization\n!pip install tf-keras","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_model_optimization as tfmot\n#import tf_keras as keras\nimport tensorflow.keras as keras\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score\n\nnp.random.seed(42)\n%load_ext tensorboard","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Boiterplate","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/dataset-2025-04-23-eps-100-changed/dataset_20250423_200322_eps_100_changed/'\ntrain_path = f'{data_dir}/train'\ntest_path = f'{data_dir}/test'\nval_set = f'{data_dir}/validation'\n\n# Resizing the images to 30x30x3\nIMG_HEIGHT = 30\nIMG_WIDTH = 30\nchannels = 3\n\nNUM_CATEGORIES = len(os.listdir(train_path))\nlr = 0.001\nepochs = 30\n\nclasses = { 0:'Speed limit (20km/h)',\n            1:'Speed limit (30km/h)', \n            2:'Speed limit (50km/h)', \n            3:'Speed limit (60km/h)', \n            4:'Speed limit (70km/h)', \n            5:'Speed limit (80km/h)', \n            6:'End of speed limit (80km/h)', \n            7:'Speed limit (100km/h)', \n            8:'Speed limit (120km/h)', \n            9:'No passing', \n            10:'No passing veh over 3.5 tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Veh > 3.5 tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End no passing veh > 3.5 tons' }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualizing The Dataset","metadata":{}},{"cell_type":"code","source":"folders = os.listdir(train_path)\n\ntrain_number = []\nclass_num = []\n\nfor folder in folders:\n    train_files = os.listdir(train_path + '/' + folder)\n    train_number.append(len(train_files))\n    class_num.append(classes[int(folder)])\n    \n# Sorting the dataset on the basis of number of images in each class\nzipped_lists = zip(train_number, class_num)\nsorted_pairs = sorted(zipped_lists)\ntuples = zip(*sorted_pairs)\ntrain_number, class_num = [ list(tuple) for tuple in  tuples]\n\n# Plotting the number of images in each class\nplt.figure(figsize=(10,5))  \nplt.bar(class_num, train_number)\nplt.xticks(class_num, rotation='vertical')\nplt.show()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Collecting the Training Data","metadata":{}},{"cell_type":"code","source":"image_data = []\nimage_labels = []\n\nfor i in range(NUM_CATEGORIES):\n    path = data_dir + '/train/' + f\"{i:02d}\"\n\n    # Skip folder of label that not exists \n    if not os.path.isdir(path):\n        continue\n    images = os.listdir(path)\n\n    for img in images:\n        try:\n            image = cv2.imread(path + '/' + img)\n            image_fromarray = Image.fromarray(image, 'RGB')\n            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n            image_data.append(np.array(resize_image))\n            image_labels.append(f\"{i:02d}\")\n        except:\n            print(\"Error in \" + img)\n\n# Changing the list to numpy array\nimage_data = np.array(image_data)\nimage_labels = np.array(image_labels)\n\nprint(image_data.shape, image_labels.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Shuffling the training data","metadata":{}},{"cell_type":"code","source":"shuffle_indexes = np.arange(image_data.shape[0])\nnp.random.shuffle(shuffle_indexes)\nimage_data = image_data[shuffle_indexes]\nimage_labels = image_labels[shuffle_indexes]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Collecting validation set","metadata":{}},{"cell_type":"code","source":"X_train = image_data.astype('float32') / 255.\n\nval_data = []\nval_labels = []\nfor label_name in os.listdir(val_set):\n    label_dir = os.path.join(val_set, label_name)\n    if not os.path.isdir(label_dir):\n        continue\n    for img_file in os.listdir(label_dir):\n        img_path = os.path.join(label_dir, img_file)\n        img = cv2.imread(img_path)\n        img = Image.fromarray(img, 'RGB').resize((IMG_HEIGHT, IMG_WIDTH))\n        val_data.append(np.array(img))\n        val_labels.append(int(label_name))\n\nX_val = np.array(val_data, dtype='float32') / 255.\n\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_val.shape\",   X_val.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## One hot encoding the labels","metadata":{}},{"cell_type":"code","source":"y_train = keras.utils.to_categorical(image_labels, NUM_CATEGORIES)\nval_labels = np.array(val_labels) \ny_val = keras.utils.to_categorical(val_labels, NUM_CATEGORIES)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_val.shape\",   y_val.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Making the model","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential([ \n    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2)),\n    keras.layers.BatchNormalization(axis=-1),\n    \n    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2)),\n    keras.layers.BatchNormalization(axis=-1),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(rate=0.5),\n    \n    keras.layers.Dense(43, activation='softmax')\n])\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def improved_model(input_shape=(IMG_HEIGHT,IMG_WIDTH,channels), num_classes=43):\n    inputs = keras.Input(shape=input_shape)\n    x = keras.layers.SeparableConv2D(32, (3,3), activation='relu', padding='same')(inputs)\n    x = keras.layers.BatchNormalization()(x)\n    # Blocco residual 1\n    res = x\n    x = keras.layers.SeparableConv2D(32,(3,3),activation='relu',padding='same')(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Add()([x, res])\n    x = keras.layers.MaxPool2D()(x)\n\n    # Blocco residual 2\n    res = x\n    x = keras.layers.SeparableConv2D(32,(3,3),activation='relu',padding='same')(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.SeparableConv2D(32,(3,3),activation='relu',padding='same')(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Add()([x, res])\n    x = keras.layers.MaxPool2D()(x)\n\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dense(128, activation='relu')(x)\n    x = keras.layers.Dropout(0.5)(x)\n    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n\n    model = keras.Model(inputs, outputs, name=\"improved_cnn\")\n    return model\n\nmodel_imp = improved_model()\nmodel_imp.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_slim = keras.models.Sequential([\n    keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(IMG_HEIGHT,IMG_WIDTH,channels),padding='same'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Conv2D(32,(3,3),activation='relu',padding='same'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    keras.layers.MaxPool2D(),\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dense(43, activation='softmax')\n], name=\"ultra_light_cnn\")\n\nmodel_slim.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### MobileNetV2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import layers, models\n\nIMG_HEIGHT_MOBILENETV2 = 32\nIMG_WIDTH_MOBILENETV2 = 32\n\ndef get_X_train_MobileNetV2():\n    image_data = []\n    image_labels = []\n    \n    for i in range(NUM_CATEGORIES):\n        path = data_dir + '/train/' + f\"{i:02d}\"\n    \n        # Skip folder of label that not exists \n        if not os.path.isdir(path):\n            continue\n        images = os.listdir(path)\n    \n        for img in images:\n            try:\n                image = cv2.imread(path + '/' + img)\n                image_fromarray = Image.fromarray(image, 'RGB')\n                resize_image = image_fromarray.resize((IMG_HEIGHT_MOBILENETV2, IMG_WIDTH_MOBILENETV2))\n                image_data.append(np.array(resize_image))\n                image_labels.append(f\"{i:02d}\")\n            except:\n                print(\"Error in \" + img)\n    \n    # Changing the list to numpy array\n    image_data = np.array(image_data)\n    image_labels = np.array(image_labels)\n    return image_data.astype('float32') / 255. , image_labels\n\ndef get_X_val_MobileNetV2():\n    val_data = []\n    val_labels = []\n    for label_name in os.listdir(val_set):\n        label_dir = os.path.join(val_set, label_name)\n        if not os.path.isdir(label_dir):\n            continue\n        for img_file in os.listdir(label_dir):\n            img_path = os.path.join(label_dir, img_file)\n            img = cv2.imread(img_path)\n            img = Image.fromarray(img, 'RGB').resize((IMG_HEIGHT_MOBILENETV2, IMG_WIDTH_MOBILENETV2))\n            val_data.append(np.array(img))\n            val_labels.append(int(label_name))\n    \n    X_val = np.array(val_data, dtype='float32') / 255.\n    return X_val, val_labels\n\nX_train_MobileNetV2, image_labels_MobileNetV2 = get_X_train_MobileNetV2()\nX_val_MobileNetV2, val_labels_MobileNetV2 = get_X_val_MobileNetV2()\n\ny_train_MobileNetV2 = keras.utils.to_categorical(image_labels_MobileNetV2, NUM_CATEGORIES)\nval_labels_MobileNetV2 = np.array(val_labels) \ny_val_MobileNetV2 = keras.utils.to_categorical(val_labels_MobileNetV2, NUM_CATEGORIES)\n\nbase = MobileNetV2(input_shape=(IMG_HEIGHT_MOBILENETV2,IMG_WIDTH_MOBILENETV2,channels), include_top=False, weights=None)\nx = base.output\nx = layers.GlobalAveragePooling2D()(x)\noutputs = layers.Dense(43, activation='softmax')(x)\nmodel_mnv2 = models.Model(inputs=base.input, outputs=outputs, name=\"mobilenet_v2\")\n\nmodel_mnv2.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Augmenting the data and training the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom keras.callbacks import LearningRateScheduler \nfrom keras.callbacks import ModelCheckpoint\n\n# Data augmentation\naug = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.15,\n    horizontal_flip=False,\n    vertical_flip=False,\n    fill_mode=\"nearest\"\n)\naugmented_train = aug.flow(X_train, y_train, batch_size=32)\n\n# Monitor learning by validation accuracy\nearly_stop = EarlyStopping(\n    monitor='val_accuracy',\n    patience=10,                \n    restore_best_weights=True,\n    verbose=1                 \n)\n\ncheckpoint = ModelCheckpoint('model.weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n\ndef lr_decay(epoch):\n    return lr * (0.5 ** (epoch // (epochs * 0.5)))\n\nif os.path.isfile('/kaggle/input/28-04-25-weights/model.weights.h5'):\n    model.load_weights('/kaggle/input/28-04-25-weights/model.weights.h5')\nelse:\n    opt = Adam(learning_rate=lr)\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=opt,\n        metrics=['accuracy']\n    )\n    \n    # Training con EarlyStopping\n    history = model.fit(\n        aug.flow(X_train, y_train, batch_size=32),\n        epochs=epochs,\n        validation_data=(X_val, y_val),\n        callbacks=[early_stop, LearningRateScheduler(lr_decay), checkpoint]\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = Adam(learning_rate=lr)\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\n# Training con EarlyStopping\nhistory_model = model.fit(\n    augmented_train,\n    epochs=epochs,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stop, LearningRateScheduler(lr_decay), checkpoint]\n)\nmodel.save_weights('model.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = Adam(learning_rate=lr)\n\nmodel_imp.compile(\n    loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\n# Training con EarlyStopping\nhistory_model_imp = model_imp.fit(\n    augmented_train,\n    epochs=50,\n    validation_data=(X_val, y_val),\n    callbacks=[LearningRateScheduler(lr_decay), checkpoint]\n)\nmodel_imp.save_weights('model_imp.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = Adam(learning_rate=lr)\n\nmodel_slim.compile(\n    loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\n# Training con EarlyStopping\nhistory_model_slim = model_slim.fit(\n    augmented_train,\n    epochs=50,\n    validation_data=(X_val, y_val),\n    callbacks=[LearningRateScheduler(lr_decay), checkpoint]\n)\nmodel_slim.save_weights('model_slim.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = Adam(learning_rate=lr)\n\nmodel_mnv2.compile(\n    loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\n# Training con EarlyStopping\nhistory_model_mnv2 = model_mnv2.fit(\n    aug.flow(X_train_MobileNetV2, y_train_MobileNetV2, batch_size=32),\n    epochs=30,\n    validation_data=(X_val_MobileNetV2, y_val_MobileNetV2),\n    callbacks=[LearningRateScheduler(lr_decay), checkpoint]\n)\nmodel_mnv2.save_weights('model_mnv2.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize=(24, 5))\n\nhistories = [history_model, history_model_imp, history_model_slim, history_model_mnv2]\nmodels = [model, model_imp, model_slim, model_mnv2]\ntitles = ['Training original model', 'Training improved model', 'Training slim model', 'MobileNetV2']\n\nfor i, (hist, model, title) in enumerate(zip(histories, models, titles)):\n    pd.DataFrame(hist.history).plot(ax=axs[i])\n    axs[i].set_title(f\"{title}\\nParams: {model.count_params():,}\")\n    axs[i].grid(True)\n    axs[i].set_ylim(0, 1)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating the model","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Quantization Optimitation ","metadata":{}},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] # default to 8bit\nquant_model = converter.convert()\n\n_, quant_model_file = tempfile.mkstemp('.tflite')\n\nwith open(quant_model_file, 'wb') as f:\n  f.write(quant_model)\n\nprint('Saved quant TFLite model to:', quant_model_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_gzipped_model_size(file):\n  # Returns size of gzipped model, in bytes.\n  import os\n  import zipfile\n\n  _, zipped_file = tempfile.mkstemp('.zip')\n  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n    f.write(file)\n\n  return os.path.getsize(zipped_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Size of gzipped baseline Keras model:\\t%.2f bytes\" % (get_gzipped_model_size(model_file)))\nprint(\"Size of gzipped quant Keras model:\\t%.2f bytes\" % (get_gzipped_model_size(quant_model_file)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the test data and running the predictions","metadata":{}},{"cell_type":"code","source":"import glob\n\nimgs = []\nlabels = []\n\nfor label_name in os.listdir(test_path):\n    label_dir = os.path.join(test_path, label_name)\n    if os.path.isdir(label_dir):\n        # Cerca immagini dentro la cartella della label\n        for img_path in glob.glob(os.path.join(label_dir, '*')):\n            imgs.append(img_path)\n            labels.append(label_name)\n\nlabels = np.array(labels).astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_predictions(model):\n    data = []\n\n    for img in imgs:\n        image = cv2.imread(img)\n        image_fromarray = Image.fromarray(image, 'RGB')\n        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n        data.append(np.array(resize_image))\n    X_test = np.array(data)\n    X_test = X_test/255\n    \n    pred = np.argmax(model.predict(X_test), axis=-1)\n    return pred, X_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Accuracy with the test data\nprint('Test Data accuracy original model: ',accuracy_score(labels, get_predictions(model)[0])*100)\nprint('Test Data accuracy improved model: ',accuracy_score(labels, get_predictions(model_imp)[0])*100)\nprint('Test Data accuracy improved model: ',accuracy_score(labels, get_predictions(model_slim)[0])*100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Weight Clustering","metadata":{}},{"cell_type":"code","source":"cluster_weights = tfmot.clustering.keras.cluster_weights\nCentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n\nclustering_params = {\n  'number_of_clusters': 16,\n  'cluster_centroids_init': CentroidInitialization.LINEAR\n}\n\n# Cluster a whole model\nclustered_model = cluster_weights(model_imp, **clustering_params)\n\n# Use smaller learning rate for fine-tuning clustered model\nopt = keras.optimizers.Adam(learning_rate=1e-5)\n\nclustered_model.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy'])\n\nclustered_model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune model\nclustered_model.fit(\n  aug.flow(X_train, y_train, batch_size=500),\n  epochs=1,\n  validation_data=(X_val, y_val)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing the confusion matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncf = confusion_matrix(labels,  get_predictions(model_imp))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\ndf_cm = pd.DataFrame(cf, index = classes,  columns = classes)\nplt.figure(figsize = (20,20))\nsns.heatmap(df_cm, annot=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Classification report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(labels, get_predictions(model)[0]))\nprint(classification_report(labels, get_predictions(model_imp)[0]))\nprint(classification_report(labels, get_predictions(model_slim)[0]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predictions on Test Data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (25, 25))\n\npred, X_test = get_predictions(model_imp)\n\nstart_index = 0\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    prediction = pred[start_index + i]\n    actual = labels[start_index + i]\n    col = 'g'\n    if prediction != actual:\n        col = 'r'\n    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n    plt.imshow(X_test[start_index + i])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}